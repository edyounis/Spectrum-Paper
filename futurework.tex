\section{Future Work}

\subsection{Bounds Check Bypass and Branch Target Injection Improvements}

While the replicated attacks are a PoC of a subset of speculative style attacks that BOOM
is susceptible to, future work can improve the secret leakage rate of the attacks.

One of the mechanisms to speed up both attacks is the improving the hand-made L1 cache line flush function
used. The current implementation uses a large extra array that is indexed into to evict a particular
cache set. Another approach, would be to just have this extra array be the size of the L1 cache and use
arithmetic to figure out which entry to index into to evict the requested cache line. This decreases the
amount of extra memory needed to run the function while allowing the statically allocated array to reside
at any memory location. Additionally, another approach to speeding up the function is to know where the
secret and probed array reside in memory. This allows the function to predetermine which addresses can be 
accessed to evict any particular line in the cache instead of doing arithmetic to index into the extra array and
having multiple branches that may misspeculate.

In addition to improving the cache line flush function, another
improvement can be to tweak the different attack parameters. This includes
the attack parameters listed in \ref{tab:attack-params}. Potentially, the amount of rounds on the
same byte and training rounds can be reduced to improve the speed of the attack.
These can be adjusted in conjunction with the cache flush hits on the same set so even though the 
random cache replacement policy may not clear all the ways of the set, the amount of rounds on
the same byte might remove the false hits when the specified line was not evicted.

\subsection{Other Attacks and More BOOM Configurations}

In addition to the two attacks that were implemented, BOOM is susceptible to a variety of
other speculative style attacks. One such example is the RSB attack, which our team was 
originally planning on implementing. However, due to BOOM not have a working configuration
with the RSB at the time, this attack was not implemented in liew of implementing the Branch Target
Injection attack. By fixing the RSB, the team could work on implementing this attack with the 
code that was initially created for it. Another improvement to the project would be to train the
variety of attacks on different branch predictors. Since BOOM provides a mechanism to add branch 
predictors and it already has a TAGE predictor, future work can use this functionality to determine
the speed of the attacks based these new predictors.

\subsection{Further Evaluations}

At the time that evaluations were occuring, BOOMs implementation of high-performance monitoring counters was not working.
With these counters, additional evaluation could occur with the counters tracking the amount of 
loads that are speculated, delayed, and more.

We plan to perform a more through evaluation of the performance and security implications of the
speculation buffer after more validation on our design is complete. We plan on running the full
SPEC suite, Coremark, and other memory intensive workloads. We also plan to configure multiple design
points of the speculation buffer with multiple implementations of the PnR head and refill/replay system.

Though the Dhrystone benchmark was able to be run, a more comphrehensive benchmark suite would be invaluable to test
the performance of the SpecBuf. At evaluation, the SpecBuf was unable to boot RISC-V Linux on FireSim and therefore
we were unable to run the SPEC2017 suite [?]. Additionally, the SpecBuf was unable to run the CoreMark EEMBC benchmark
suite due to bugs that occured 5M cycles into the suite. Thus, future work would be to fix the bugs preventing these
benchmarks to run and reevaluate the results of the paper based on this new data.

Get better synthesis data from HAMMER [?]. Instead of using flops use sram to have a minimal 
physical impact.

\subsection{BOOM Improvements}

Future work for the project also involves bringing BOOM to a more stable version. Throughout
the project, a multitude of performance-reducing bugs were found both in the front-end (fetch stage, BPU, etc) and the 
load/store unit that the team had to work around. With these fixed, not only will performance
of the core improve, but other replication and modifications to the core will be easier since
the base core will be stable and provide more reliable performance metrics.

\subsubsection{Multiported Cache}
The non-blocking L1 data cache employed in BOOM was designed with the in-order Rocket core in mind; is not ideal for
a high performance out-of-order core. This is for several reasons.

Firstly the cache does not have any concept of speculative execution.
In the baseline version of BOOM, this is bridged with an external ``data cache shim'' stucture. We have further introduced the cache to the
concept of speculative execution by propagating the necessary signals through the first two stages and into the MSHR file.

Second, the cache contains many structures and provisions which are superfluous in an out-of-order core.
For instance, the job of the replay queues would be better handled by the core's load/store unit itself.

Finally, the cache is strictly single ported. In order to investigate high performance variants of the BOOM core,
a multiported data cache will be required.

\subsubsection{Speculation Buffer Improvements}
Our current speculation buffer implementation has several limitations, mentioned in \ref{Speculation Buffer}.
Among them are the lack of full-associativity, the inability to immediately deallocate killed MSHRs, and MSHR state sequences which are not fully optimized.
We may be able to implement some of these improvements in our proof-of-concept speculation buffer, but others would be more difficult. To improve further upon
our proof-of-concept, we may be better served by looking at re-architecting BOOM's data cache with speculative safety in mind. This builds upon our other thoughts
on BOOM's data cache mentioned above.

\subsubsection{Multi-level Cache Hierarchy}
The current speculation buffer addresses only a single level cache hierarchy.
BOOM is currently configured with an L1 data cache and a large scratchpad memory.
In the future, it would be valuable to configure BOOM with a more realistic cache hierarchy,
such as with a large L2 shared between several cores. This would lend towards an extension of the speculation
buffer strategy to protect this realistic hierarchy.
