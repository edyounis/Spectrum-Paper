\section{Future Work} \label{Future Work}

\subsection{Bounds Check Bypass and Branch Target Injection Improvements}

The replicated attacks are only a subset of speculative style attacks that out-of-order
microarchitectures are susceptible to. In future work, we plan on both improving the efficiency of
our replicated attacks, and demonstrating more variants of these exploits.

One potential mechanism to speed up both attacks is to improve our hand-made L1 cache line flush
function. The current implementation indexes a large extra array to to evict a particular cache set.
Another approach, would be to just have this extra array be the size of the L1 cache and use
arithmetic to figure out which entry to index into to evict the requested cache line.
This decreases the amount of extra memory needed to run the function while allowing the statically
allocated array to reside at any memory location. Additionally, if the attacker knew the addresses of
the secret and probe arrays, it could more precisely determine which cache lines to evict and test.

In addition to improving the cache line flush function, another
improvement can be to tweak the different attack parameters. This includes
the attack parameters listed in Table \ref{tab:attack-params}. Potentially, the amount of rounds on the
same byte and training rounds can be reduced to improve the speed of the attack.
These can be adjusted in conjunction with the cache flush hits on the same set so even though the 
random cache replacement policy may not clear all the ways of the set, the amount of rounds on
the same byte might remove the false hits when the specified line was not evicted.

\subsection{Other Attacks and More BOOM Configurations}

BOOM is susceptible to a variety of other speculative style attacks. One such example is the RSB
attack. In the future, we plan on fixing BOOM's RSB so we can demonstrate this exploit.
Another improvement to the project would be to train the attacks on different branch predictors.
Specifically, we would like to evaluate the efficiency of these attacks on a high-performance
TAGE predictor.

\subsection{Further Evaluations}

We plan to perform a more thorough evaluation of the performance and security implications of the
SpecBuf with more workloads, in addition to Dhrystone. At evaluation, the SpecBuf was unable to boot
RISC-V Linux on FireSim and therefore we were unable to run the SPEC2017 suite and the CoreMark EEMBC benchmark \cite{b50, b51}.
Currently, RISC-V Linux runs for around 180M cycles before a pipeline assertion fires in FireSim simulation. However, 
in VCS simulation, Linux runs for over 350M cycles. Further work needs to be done to see if the VCS simulation
fully boots Linux as well as checking the difference between the VCS and FireSim simulations. After fixing the Linux boot, we
plan to perform a more thorough evaluation of the SpecBuf. We plan to configure multiple design
points of the SpecBuf with multiple implementations of the PNR head and refill/replay system,
and compare the tradeoffs of each implementation.

\subsection{BOOM Improvements}

Future work for the project also involves bringing BOOM to a more stable version. Throughout
the project, many performance-reducing bugs were found in the front-end. Work done after
evaluation has resulted in the RSB being reconnected, fixes to GShare Branch History
Table counters and Branch History Register hashing to allow for better predictions.
The changes improve the branch prediction of both baseline and the SpecBuf version of the core resulting in
higher Dhrystone scores (the SpecBuf version shows a 26\% improvement in Dhrystone results). 
However, there are still more front-end bugs that can be addressed for further improvements.
Additionally, the LSU unit does not currently support the updated RISC-V WMO memory model.
Resolving these issues would not only improve the performance of our replicated attacks,
it would also further validate BOOM as a platform for secure hardware research.
Beyond the above, we have additionally identified several broad areas for future BOOM improvements.

\subsubsection{Multi-ported Cache}

The non-blocking L1 data cache employed in BOOM was designed with the in-order Rocket core in mind;
is not ideal for a high performance out-of-order core. The cache does not have any concept of
speculative execution, and contains many structures and provisions which are superfluous in an
out-of-order core. Some of the L1 structures, like the replay queues and store data queues, would be
better handled within the core's load/store unit itself.
Additionally, the cache is strictly single ported. In order to investigate higher performance variants
of the BOOM core, a multi-ported data cache will be required.

\subsubsection{SpecBuf Improvements}

Our current SpecBuf implementation has several limitations, described in Section \ref{specbuf_sidechannel}.
Among them are the lack of full-associativity and the inability to immediately deallocate killed MSHRs.
To improve further upon our initial design, we may want to rearchitect BOOM's data cache from
the ground up with speculative safety in mind.

\subsubsection{Multi-level Cache Hierarchy}

The current SpecBuf addresses only a single level cache hierarchy.
BOOM is currently configured with an L1 data cache and a large all-encompassing L2.
In the future, it would be valuable to configure BOOM with a more realistic cache hierarchy,
such as with a large L2 shared between several cores. The technique described in this paper
could be potentially extended to support multi-level cache hierarchies.
