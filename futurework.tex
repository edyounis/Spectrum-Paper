\section{Future Work}

\subsection{Bounds Check Bypass and Branch Target Injection Improvements}

The replicated attacks are only a subset of speculative style attacks that out-of-order
microarchitectures are susceptible to. In future work, we plan on both improving the efficiency of
our replicated attacks, and demonstrating more variants of these exploits.

One potential mechanism to speed up both attacks is to improve our hand-made L1 cache line flush
function. The current implementation indexes a large extra array to to evict a particular cache set.
Another approach, would be to just have this extra array be the size of the L1 cache and use
arithmetic to figure out which entry to index into to evict the requested cache line.
This decreases the amount of extra memory needed to run the function while allowing the statically
allocated array to reside at any memory location. Additionally, if the attacker knew the addresses of
the secret and probe arrays, it could more precisely determine which cache lines to evict and test.
%the function to predetermine which addresses can be accessed to evict any particular line in the cache instead of doing arithmetic to index into the extra array and having multiple branches that may misspeculate.

In addition to improving the cache line flush function, another
improvement can be to tweak the different attack parameters. This includes
the attack parameters listed in \ref{tab:attack-params}. Potentially, the amount of rounds on the
same byte and training rounds can be reduced to improve the speed of the attack.
These can be adjusted in conjunction with the cache flush hits on the same set so even though the 
random cache replacement policy may not clear all the ways of the set, the amount of rounds on
the same byte might remove the false hits when the specified line was not evicted.

\subsection{Other Attacks and More BOOM Configurations}

BOOM is susceptible to a variety of other speculative style attacks. One such example is the RSB
attack. In the future, we plan on fixing BOOM's RSB so we can demonstrate this exploit.
Another improvement to the project would be to train the attacks on different branch predictors.
Specifically, we would like to evaluate the efficiency of these attacks on a high-performance
TAGE predictor.

\subsection{Further Evaluations}

We plan to perform a more through evaluation of the performance and security implications of the
SpecBuf with more workloads, in addition to Dhrystone. At evaluation, the SpecBuf was unable to boot
RISC-V Linux on FireSim and therefore we were unable to run the SPEC2017 suite \cite{b50}.
Additionally, the SpecBuf was unable to run the CoreMark EEMBC benchmark suite due to bugs that
occurred 5M cycles into the suite \cite{b51}. We plan to resolve these bugs and perform a more
thorough evaluation of the SpecBuf. We also plan to configure multiple design
points of the SpecBuf with multiple implementations of the PnR head and refill/replay system, and compare the tradeoffs of each implementation.

%Get better synthesis data from HAMMER \cite{b52}. Instead of using flops use sram to have a minimal 
%physical impact.

\subsection{BOOM Improvements}

Future work for the project also involves bringing BOOM to a more stable version. Throughout
the project, many performance-reducing bugs were found both in the front-end and the 
load/store unit. Resolving these bugs would not only improve the performance our replicated attacks,
it would also further validate BOOM as a platform for secure hardware research.

\subsubsection{Multi-ported Cache}
The non-blocking L1 data cache employed in BOOM was designed with the in-order Rocket core in mind;
is not ideal for a high performance out-of-order core. The cache does not have any concept of
speculative execution, and contains many structures and provisions which are superfluous in an
out-of-order core. Some of the L1 structures, like the replay queues and store data queues, would be
better handled within the core's load/store unit itself.
Additionally, the cache is strictly single ported. In order to investigate high performance variants
of the BOOM core, a multi-ported data cache will be required.

\subsubsection{SpecBuf Improvements}
Our current SpecBuf implementation has several limitations, mentioned in \ref{specbuf}.
Among them are the lack of full-associativity, the inability to immediately deallocate killed MSHRs,
and MSHR state sequences which are not fully optimized.
To improve further upon our initial design, we would want to rearchitect BOOM's data cache from
the ground up with speculative safety in mind. 

\subsubsection{Multi-level Cache Hierarchy}
The current SpecBuf addresses only a single level cache hierarchy.
BOOM is currently configured with an L1 data cache and a large all-encompassing L2.
In the future, it would be valuable to configure BOOM with a more realistic cache hierarchy,
such as with a large L2 shared between several cores. The technique described in this paper
could be potentially extended to support multi-level cache hierarchies.
